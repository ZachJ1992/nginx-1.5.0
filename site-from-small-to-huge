网站从蚂蚁变大象

1.  简单的网站
    Web Server + 逻辑代码 + 数据库
    Web Server : Web服务器，比如Apache, Nginx, IIS等
    逻辑代码 : 采用jsp, asp, php等页面语言来搭建简单的业务逻辑
    数据库 : 通用关系数据库MySQL, SQL Server等。

    不过这个阶段的逻辑代码，既要负责处理请求参数， 又要处理各种逻辑， 还要负责链接数据库，以及页面的展示， 代码可重用性和可维护性不是太好。

2.  增强代码可重用性和可维护性
    这个解阶段， 机器数量没有增加， 只是对逻辑代码进行了重构， 引入MVC。

    通过MVC使得逻辑代码的可重用性和可维护性得到增强。从性能上会有所下降， 因为框架的使用， 使得程序的执行效率降低。

    在应对不是很高的业务量时是没有太大问题的。

3.  降低磁盘压力
    业务持续发展， 请求量势必增加， 这个时候就会出现磁盘性能的瓶颈。

    在我们的计算机课程中有讲到:
        CPU Cache        价格昂贵、存储量小、访问速度快
        Memory           价格适中、存储量稍大，访问速度稍快
        Disk             价格便宜、存储量大、访问速度慢

    磁盘出现瓶颈， 压力增大， 可以考虑内存上的替代方案， 但需要正视的一个现实问题就是， 内存是非持久化介质。 断电后数据会丢失， 因此， 内存还是只能保存临时性的数据， 持久性数据还是要放到磁盘等持久化介质上。

    内存可以用来实现Cache. 通常采用LRU(Least Recently Used 最近最少使用)的算法， 还可结合队列， 集合等多种数据结构， 以及排序等多种算法的cache.

    可用的内存缓存有Memcached, Redis等内存数据库， 保存临时性的缓存信息， 采用key-value对来保存数据。

    这样在这个阶段， 就可以在数据库前面放一个缓存， 来减少磁盘压力。 
    首先从Cache中获取数据， 如果数据存在且有效， 就直接返回结果; 如果数据不存在， 则从数据库获取， 经过逻辑处理后， 先写入缓存， 然后再返回给用户数据。 

    需要注意的问题是， 调整内存大小， 保证有足够的命中率。
    另外一个问题是， Cache出问题(挂掉了)， 那么就杯具了， 服务器就会将大的压力压向数据库， 造成服务响应慢， 或者直接500(服务器遇到一个错误， 无法为请求提供服务)。

    最后要注意的是， 服务重启的时候， 也会出现慢启动， 即： 给Cache充数据的阶段， 可以采取回放日志， 或者从数据库抽取最新数据等方式， 在服务器启动前，提前将一部分数据放到Cache中， 保证有一定的命中率。

4.  服务多机化
    在IO性能得到解决以后， 可能面临CPU的瓶颈， 程序处理不过来。
    这个时候， 一方面考虑优化程序， 从整体架构和具体业务逻辑上去分析并做优化。
    比如反射， 正则表达式， 字符串拼接， 内存拷贝等是CPU耗费比较多的地方， 可以着重优化。 通过程序的优化， 可以将性能提升30-40个百分点。

    如果优化后还是不能满足需求， 那就可以考虑硬件的更换， 换更好的服务器。

    假设换服务器也不能满足日益增大的业务需求， 也是值得恭喜的， 因为现在的访问量已初具规模了， 那么是时候考虑多机化服务了。

    多机是小网站从技术架构上要迈出的第一步， 也是一个质的飞跃的阶段。

    最简单的就是将Web Server和Cache + DB搬到其他的机器上去， 利用Web Server、 DB和Cache的网络协议对它们进行访问。 这样原本被它们占用的CPU就可以空出来处理逻辑程序使用。

    大概提升20-30的CPU idle。 这时也能经受更大的压力了。

5.  逻辑程序的多机化
    当访问量持续增加的时候， 流量唰唰上涨， 高兴之余， 服务器就痛苦不堪， 程序就快达到不能服务的边缘了。 怎么办呢? 

    分布式处理啊！ 这时候依然是针对的CPU瓶颈， 考虑将逻辑程序分别放在多台服务器上， 让它们同时提供服务， 将用户的请求分摊到多个提供服务器的机器上。

    问题：
        1) Web Server如何来分流用户请求?
            这个问题比较好解决， 大多数的Web Server都提供这样的服务， 叫做"Load Banlance"， 即负载均衡。 可以在Web Server上配置一组机器列表， 当请求来临的时候， Web Server就会根据一定的规则来选取某一台机器， 将请求转发到对应的逻辑处理程序上。
            这里负载均衡的算法规则，不详细介绍， 无非是使用随机， 轮询， 一致Hash等算法来实现选择具体的机器；
            使用心跳，服务响应判定等方法检测机器的健康状态。
        2) 用户的Session如何来同步?
            HTTP协议是一个无状态的服务协议， 但是，用户的基本信息是要求能够保证的。就是通过Session来解决的。但是对于多机的时候， Session的同步就成为问题。 比如，用户某次在某台机器登录， 记录了Session， 但下次请求到达的是另外一台机器， 结果就变成未登录状态。 这样是很不合理的。
            问题: 1. 一台机器登录， 其他机器不知道
                  2. 用户请求可能到达多台机器
            问题1， 如果让一台机器的登录信息告知其他机器，或者大家都在一台机器登录 问题解决了。
            问题2， 我们让同一个用户的请求落在同一台机器， 问题也解决了。

            方案: 
                1. 提供session同步机制
                2. 提供统一session服务
                3. 将同一用户分流到同一机器
            比较好的方式是采用memcache的方式来同步session。
            所有的请求session都由memcache集群来管理， 就能达到session统一。
        3) 数据访问的同步问题?
            多个请求同时到达， 并且竞争同一资源的时候(比如秒杀， 或者订火车票)。

            我们现在用到的是单机数据库， 可以在需要竞争的资源上加锁， 用于同步资源的请求。 但这个东西不是万能的， 锁会极大的影响效率， 所以尽可能的减少锁的使用， 并且已经使用锁的地方尽量优化， 并检查可能出现死锁。

            Cache也有对应的解决方案， 比如延迟删除或者冻结时间等技术， 就是让资源在一段时间处于不可读的状态， 用户直接从数据库查询， 这样保证数据的有效性。

    附上Nginx简单负载均衡的配置:
user  www www;
worker_processes 10;
#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;
#pid        logs/nginx.pid;
#最大文件描述符
worker_rlimit_nofile 51200;
events
{
      use epoll;
      worker_connections 51200;
}
http
{
      include       conf/mime.types;
      default_type  application/octet-stream;
      keepalive_timeout 120;
      tcp_nodelay on;
      // 负载均衡机器IP:port列表
      upstream  www.xxx.com  {
              server   192.168.1.2:80;
              server   192.168.1.3:80;
              server   192.168.1.4:80;
              server   192.168.1.5:80;
      }
      server
      {
              listen  80;
              server_name  www.xxx.com;
              // 这里的请求全部转发
              location / {
                       proxy_pass        http://www.s135.com;
                       proxy_set_header   Host             $host;
                       proxy_set_header   X-Real-IP        $remote_addr;
                       proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;
              }
              log_format  www_s135_com  '$remote_addr - $remote_user [$time_local] $request '
                                '"$status" $body_bytes_sent "$http_referer" '
                                '"$http_user_agent" "$http_x_forwarded_for"';
              access_log  /data1/logs/www.log  www_s135_com;
      }
}

6.  读写分离, 提升IO性能
    在提交增长， 查询量不断增加的情况下， 会带来存储性能的瓶颈。
    这个时候， 单机数据库可能已经逐步成为瓶颈， 数据库出现比较严重的读写冲突(即: 多个线程或者进程因为读写需要， 争抢磁盘， 使得磁盘的磁头不断变换磁道或者此片， 造成读写都很缓慢)。

    解决办法:
    1)  减少读取量
        问题来源就是因为读写量增加, 看起来这个是最直接最根源的解决办法。 不过， 用户有那么大的请求量我们怎么能减少呢? 其实, 对于越后端的系统， 这是越可能的事情。我们可以在每一层都减少一部分往后传输的请求。
        具体到数据库的话， 我们可以考虑通过增加Cache命中率。 增加Cache命中率的方法有很多种: 比如对业务访问模式进行优化、多级Cache模式、增加内存容量等等。
        业务模式的修改不是太好通用， 因此我们可以考虑如果通过增加内存容量来解决问题。
        对于单机， 现在通用的cache服务一般都可以配置内存大小， 这个只需要很简单的配置即可。 另外， 我们也可以考虑多机cache的方案， 通过增加机器来扩充内存容量。因此，我们就引入了分布式cache， 现在常用的cache(memcache)都带有这样的功能， 支持多机cache服务， 可以通过负载均衡算法， 将请求分散到多台不同的机器上， 从而扩充内存容量。

        这里需要强调一点。 在我们选择均衡算法的时候，是有考虑的。 这个时候， 常常选择一致Hash算法， 将某一系列ID分配到固定的机器， 这样的话， 能放的KV对基本等于所有机器相加。 否则，如果不做这样的分配， 所有机器内存里边的内容会有大量重复， 内存并没有很好的利用。 另外， 因为采用一致Hash， 即使一台机器宕机， 也会比较均匀的分散到其他机器， 不会造成瞬间其他机器cache大量失效或不命中的问题。

    2)  减少写入量
        要减少用户的提交， 这个看起来不太现实的。 确实， 我们要减少写入的量似乎是很难的一件事。 不过也不是完全不可能。 这里我们会提到一个思想: 合并写入。
        就是将有可能的写入在内存里进行合并， 到一定时间或是一定条件后， 再一起写入。其实，在Mysql等存储引擎内部， 都是有这样的机制的。 打个比方， 比如有一个逻辑是修改用户购买物品的数量， 每次用户购买物品后， 计数都加1. 如果我们现在不是每次都实时写磁盘， 而是到一定的时间或一定次数后， 再写入， 这样就可以减少大量的写入操作。 但是这里需要考虑， 如果服务器宕机以后，内存数据的恢复问题。

        因此， 如果想简单的使用数据合并， 最好是针对数据重要性不是很强的业务， 即使丢掉一部分数据， 也没有关系。

    3)  多机承担请求， 分散压力。
        如果将原来的单机服务，扩充成多机， 这样我们就能很好的将处理能力在一定限度内很好的扩展。

        我们常用的有数据同步和数据订阅。
        数据同步: 将所有的更新数据发送到一台固定的数据服务器上，由数据服务程序处理后，通过日志等方式，同步到其他机器的数据服务程序上。
                            |
                    +-------+-------+
                    | 存储逻辑和数据|
                    |    (Master)   |
                    +---------------+
                           /  \
                          /    \
                         /      \
                        /        \
                       /          \
                      /            \
                     /              \
                    /                \
            +--------------+  +----------------+
            |存储结构和数据|  | 存储结构和数据 |
            |    (Slave)   |  |    (Slave)     |
            +--------------+  +----------------+
                        (数据同步)
        这种结构的好处是, 我们的数据基本能保证最终的一致性(即:数据肯能在短暂时间内出现不一致， 但最后的数据能达到一致)，而且结构比较简单， 扩展性较好。
        另外，如果我们需要实施数据， 我们可以通过查Master就行。
        但是问题也比较明显， 如果负责处理和分发的机器挂掉了，我们就需要考虑单点备份和切换方案。

        数据订阅: 我们可以通过这样的方式来解决数据多机更新的问题。这种模式即是在存储逻辑和数据前，增加一个叫做Message Queue(消息队列,简称MQ)的东西，前端业务逻辑将数据直接提交到MQ，MQ将数据做成排队等操作， 各个存储系统订阅自己想要的数据， 然后让MQ推送或自己拉取需要的数据。
                            |
                    +-------+-------+
                    | Message Queue |
                    +---------------+
                           /  \
                          /    \
                         /      \
                        /        \
                       /          \
                      /            \
                     /              \
                    /                \
            +--------------+  +----------------+
            |存储结构和数据|  | 存储结构和数据 |
            |    (主机1)   |  |    (主机2)     |
            +--------------+  +----------------+

        MQ不带任何业务处理逻辑， 它的作用就是数据转发， 将数据转发给需要的系统。
        其他系统拿到数据后， 自行处理。

        这样的结构， 好处是扩展比较方便， 数据分发效率很高。 但是问题也比较明显， 因为处理逻辑分散在各个机器，所以数据的一致性难以得到保证。 另外，因为这种模式看起来就是一个异步提交的模式， 如果想得到同步的更新结果， 要做很多附加的工作， 成本很高且耦合度很大。 
        还有， 需要考虑MQ的单点备份和切换问题。

        因为现在的数据Mysql基本带有数据同步功能， 因此我们在这个阶段比较推荐数据同步的方法。 至于第二种方式，其实是很好的一种思想， 后续我们会有着重的提及。

    到目前阶段， 我们基本上实现了从单机到多机的转变。 数据的多机化，必然带来的问题:一致性!

    这个是否有解决方案? 这个时候我们需要引入一个著名的理论: CAP原理。

    CAP原理包含三个要素: 一致性(Consistency), 可用性(Availability), 分区容忍性(Partition tolerance)。
    三个要素中，最多只能保证两个要素同时满足， 不能三者兼顾。

    架构设计时， 要根据业务需要进行取舍。 比如，我们为了保证可用性和分区容忍性， 可能会舍去一致性。

    我们将数据分成多机， 提高了系统的可用性， 因此， 一致性的保证很难做到强一致性。 有可能做到最终一致性。 这也是分布式引入以后的烦恼。

7)  拆分
    直到上一步，我们初步接触到了逻辑、存储等的多机模式。 这样的结构，对于逻辑不是特别复杂的网站， 足以撑起千万级的压力。 所以大多数网站，只要能够用好上面的结构就可以很好的应对服务压力了。 只不过还有很多细节的工作需要精细化， 比如:多机的运维、稳定性的监控、日志的管理、请求的分析与挖掘等等。
    如果流量持续增长，或者是业务持续的扩展，上述的架构可能又将面临挑战。
    比如，多人开发常常出现版本冲突，对于数据库的更新量变大；一个表里的记录数已经超过千万甚至过亿等等。

    怎么解决呢? 我们前面介绍了CAP理论， 三要素里边有一个叫做分区容忍性。 其实，这个就是我们下面来解决问题的基础:切分!

    一. 从数据流向来看，切分包括: 请求的切分、逻辑的切分、数据的切分。
    请求的切分: 将不同的数据放到不同的库中，将原来的单一的一个库，切分成多个库。

    逻辑的切分: 将不同的业务逻辑拆分成多份代码， 用不同的代码管理路径来管理(如svn).

    请求的切分: 将不同的逻辑请求分流到不同的机器上. 比如: 图片请求、视频请求、注册请求等。

    二. 从数据组织来看，切分包括: 水平切分、垂直切分
    数据库的变大通常是朝着两个方向来进行的, 一个是功能增加，导致表结构横向扩展; 一个是提交数据持续增多, 导致数据库表里的数据量持续纵向增加。

    数据量变大以后，单机性能会下降很明显， 因此我们需要在合适的时候对数据进行切分.

    垂直切分和水平切分，其实是挺纠结的两个词：
    水平切分: 横着来一刀,将原来的一张表里边的数据存入到多张表中，用于减少单张表里的数据量。

    垂直切分: 竖着来一刀,将原来的一张表里边的所有字段, 拆分成多张表，通过某一个key来做关联(如关系数据库中的外键)， 从而避免大表的产生。

    好了，有了上述的基础之后， 我们再来看实际问题如何来解决。
    假设，现在我们有一个博客网站，这个网站拥有多个功能，如:图片、博客、用户信息等的插查删改操作。 而现在的博客数据膨胀比较厉害。

    首先，我们从数据流向来看， 用户访问博客、图片、用户信息等这几个逻辑没有直接的耦合，对应的业务逻辑关联也很少。因此，我们第一步从入口上就可以把三者分开。 最简单的方式就是通过域名来切分，比如img.xxx.com, blog.xxx.com, user.xxx.com.然后通过不同的Web Server来接收这些请求。

    第二步，我们的业务逻辑代码，很明显可以将这些逻辑分开(从部署上分开)。 一部分专门处理图片的请求，如ImageUploadAction/ImageDisplayAction/ImageDeleteAction,一部分专门处理博客请求:BlogDisplayAction/BlogDeleteAction,一部分专门处理用户相关请求，如:UserModifyAction/UserDisplayAction等等。

    第三步，从数据库存储上，将三者剥离开。 简单的就是分成三个不同的库。
    这样，从数据流向上，我们就按不同的功能，将请求进行了拆分。

    其次， 从数据存储上来看， 由于博客数据量增长比较快， 我们可以将博客的数据进行水平的拆分。 拆分的方法很多，比如常用的:
    1) 按区间拆分。假定我们用blog_id作为key， 那么我们可以每1KW，做一次切分。 比如[1, 1kw), [1kw, 2kw)...... 这样做的好处就是可以不断的增长。 但访问可能会因为博客新旧的原因， 其中到最新的几个库或者表中。 另外，要根据数据的增长动态的建表。

    2) 按取模拆分。 比如我们估计我们的blog_id最多不超过10亿，如果每张表里边我们预估存入1千万的数据， 我们就需要100张表(或库)。 我们就可以按照blog_id%100这样做切分。 这样做的好处是简单， 表在一开始就创建好了。 且每个表或者库的访问都比较均匀。 但问题是， 如果数据持续扩张， 超出预期， 那么扩展性就成为最主要的问题。
    3) 还有其它一些衍生的方式，比如按hash值进行切分等等，大同小异。

    这样一来， 我们通过访问模式、数据组织等多个维度的拆分以后，我们的单机能够提供的服务能力就变得比较强悍了。 具体的架构如下图:
                        ----+-----------------------------------|
                            |                           +-------+-------+
                            |                           |  Web Server 2 |
                            |                           +---------------+
                            |                                   |
                            |                           +-------+-------+
                            |                           |      逻辑     |
                            |                           +---------------+
                            |                                  /  \
                            |                                 /    \
                            |                                /      \
                            |                               /        \
                            |                              /          \
                            |                             /            \
                            |                            /              \
                            |                           /                \
                            |                   +--------------+  +--------------------+
                            |                   |    Cache     |  |DB(Data Split n - m |
                            |                   +--------------+  +--------------------+
                            |
                            |
                    +-------+-------+
                    |  Web Server 1 |
                    +---------------+
                            |
                    +-------+-------+
                    |      逻辑     |
                    +---------------+
                           /  \
                          /    \
                         /      \
                        /        \
                       /          \
                      /            \
                     /              \
                    /                \
            +--------------+  +--------------------+
            |    Cache     |  |DB(Data Split 1 - n |
            +--------------+  +--------------------+

    上面的结构看似完美， 但实际的使用中可能遇到下面问题:
    1) 业务关联问题 : 多个Service之间不可能没有任何关联，怎么办?特别是如果是提交的信息要修改多个业务数据的时候，这个会比较头疼。
    2) 服务运维问题 : 这样拆分以后，随着机器数量的膨胀，对机器的管理将会变得愈发的困难。 这个问题直接会影响到整体架构的设计。 面向运维的设计是架构设计中必须要考虑的重要因素。
    3) 还有一个问题是我们WebServer始终是单机的，如果出现宕机的问题， 那影响将是致命的。 这个我们还没有解决。

8)  Web Server的多机化
    上面说的都是一个web server的情况，如果它出现宕机，所有服务就停掉了；如果压力大了， 单机不能承载了，怎么办?

    Client ---Request---> URL ----->  请求DNS服务器
           <-----------------------返回IP地址
           ----------->    请求给定IP的服务器
           <-----------    服务器返回数据

    上面的过程，我们应该比较熟悉，同时也应该比较清晰的表达了我们简化后，从输入网址到页面展现的一个过程。 中间有两个东西我们比较关注， 也是解决我们Web Server多机化的关键。
    1) DNS服务是否能帮助我们解决多机化?
    2) www.xxx.com服务器的Web Server如何多机化?
    首先， 如果DNS解析能够根据我们的请求来区分， 对于同一个域名，将不同的用户请求，绑定到不同的ip上， 这样，我们就能部署多个Web Server，对应不同的ip， 剩下的无非就是申请几个IP地址而已。

    当我们网站比较小的时候，我们都是在代理商处购买域名并由代理商的服务域名解析服务器帮我们做域名解析。 但是，对于许多大型的网站， 都需要对类似于www.xxx.com, blog.xxx.com, img.xxx.com等在xxx.com根下的所有服务进行域名解析，这样便于对服务进行控制和管理。 而域名的解析往往有专门的策略来处理， 比如根据ip地域、根据不同请求IP的运营商等返回不同的服务器IP地址。
                       |             +
                       |             |
                       +             |
                  +-------------------------+
                  |    DNS Server           |
                  +-------------------------+
                               +
                               |
                               +
                        +---------------+
                        | DNS策略分析   |
                        | 和处理服务    |
                        +---------------+
    DNS策略分析和处理服务是对请求IP进行分析和判断的系统， 判断请求来自哪个地域、哪个运营商，然后根据内部的一些库的判断，决定应该返回哪个Web Server的IP。这样，就能尽量保证用户以最快的速度访问到对应的服务。

    但是，如果我们有大量的Web Server，那每个Server都要有一个IP， ，又要申请一个IP地址，好像很麻烦，而且不能接受。 怎么办呢?

    第二点，我们需要考虑对于服务器的Web Server的多机化方式
    我们为什么要Web Server多机化? 原因就是因为单机的处理性能不行了， 我们要提升处理能力。
    那Web Server要做哪些事情?Hold住大量用户请求连接；根据URL请求分流到不同的逻辑处理的服务器上；有可能还有一些防攻击策略等。 其实这些都是消耗CPU的。

    如果我们在Web Server前端增加一层， 什么逻辑都不处理， 就是利用一定的负载均衡策略将数据包转发给Web Server(工作在IP层，非TCP层)。 那这一层的处理能力跟WebServer比是否要强悍很多? 这样的话， 这后一层就可以挂载很多Web Server， 而无需增加外网IP。 我们暂且叫这一层叫VS(Virtual Server). 这一层服务要求稳定性较高， 且处理逻辑要极为简单， 同时最好工作在网络模型中较低的层次上。

    